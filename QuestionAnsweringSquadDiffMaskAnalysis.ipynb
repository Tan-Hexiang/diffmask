{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from diffmask.models.question_answering_squad_diffmask import (\n",
    "    BertQuestionAnsweringSquadDiffMask,\n",
    ")\n",
    "from diffmask.utils.plot import plot_squad_attributions, print_attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--gpus\", type=str, default=\"0\")\n",
    "    parser.add_argument(\"--model\", type=str, default=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "    parser.add_argument(\n",
    "        \"--train_filename\",\n",
    "        type=str,\n",
    "        default=\"./datasets/squad/train-v1.1_bert-large-uncased-whole-word-masking-finetuned-squad.json\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--val_filename\",\n",
    "        type=str,\n",
    "        default=\"./datasets/squad/dev-v1.1_bert-large-uncased-whole-word-masking-finetuned-squad.json\",\n",
    "    )\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=16)\n",
    "    parser.add_argument(\"--gate_bias\", action=\"store_true\")\n",
    "    parser.add_argument(\"--seed\", type=float, default=0)\n",
    "    parser.add_argument(\n",
    "        \"--model_path\",\n",
    "        type=str,\n",
    "        default=\"models/squad-diffmask-input.ckpt\",\n",
    "#         or\n",
    "#         default=\"models/squad-diffmask-hidden.ckpt\",\n",
    "    )\n",
    "\n",
    "    hparams, _ = parser.parse_known_args()\n",
    "    \n",
    "    torch.manual_seed(hparams.seed)\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = hparams.gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33f2082064af4ba4a35c7ada959120ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda:0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mBertQuestionAnsweringSquadDiffMask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mfreeze()\n",
      "File \u001B[0;32m~/workplace/diffmask/venv/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py:1522\u001B[0m, in \u001B[0;36mLightningModule.load_from_checkpoint\u001B[0;34m(cls, checkpoint_path, map_location, tags_csv, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1519\u001B[0m     hparams\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mon_gpu\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   1520\u001B[0m     checkpoint[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhparams\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mvars\u001B[39m(hparams)\n\u001B[0;32m-> 1522\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_model_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/workplace/diffmask/venv/lib/python3.9/site-packages/pytorch_lightning/core/lightning.py:1552\u001B[0m, in \u001B[0;36mLightningModule._load_model_state\u001B[0;34m(cls, checkpoint, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1550\u001B[0m \u001B[38;5;66;03m# load the state_dict on the model automatically\u001B[39;00m\n\u001B[1;32m   1551\u001B[0m model_args \u001B[38;5;241m=\u001B[39m [hparams] \u001B[38;5;28;01mif\u001B[39;00m hparams \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[0;32m-> 1552\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1553\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(checkpoint[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstate_dict\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m   1555\u001B[0m \u001B[38;5;66;03m# give model a chance to load something\u001B[39;00m\n",
      "File \u001B[0;32m~/workplace/diffmask/diffmask/models/question_answering_squad_diffmask.py:222\u001B[0m, in \u001B[0;36mBertQuestionAnsweringSquadDiffMask.__init__\u001B[0;34m(self, hparams)\u001B[0m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, hparams):\n\u001B[0;32m--> 222\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    224\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mParameterList(\n\u001B[1;32m    225\u001B[0m         [\n\u001B[1;32m    226\u001B[0m             torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mParameter(torch\u001B[38;5;241m.\u001B[39mones(()))\n\u001B[1;32m    227\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnet\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    228\u001B[0m         ]\n\u001B[1;32m    229\u001B[0m     )\n\u001B[1;32m    231\u001B[0m     gate \u001B[38;5;241m=\u001B[39m DiffMaskGateInput \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhparams\u001B[38;5;241m.\u001B[39mgate \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m DiffMaskGateHidden\n",
      "File \u001B[0;32m~/workplace/diffmask/diffmask/models/question_answering_squad_diffmask.py:30\u001B[0m, in \u001B[0;36mQuestionAnsweringSquadDiffMask.__init__\u001B[0;34m(self, hparams)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, hparams):\n\u001B[0;32m---> 30\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameters():\n\u001B[1;32m     33\u001B[0m         p\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/workplace/diffmask/diffmask/models/question_answering_squad.py:187\u001B[0m, in \u001B[0;36mBertQuestionAnsweringSquad.__init__\u001B[0;34m(self, hparams)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, hparams):\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(hparams)\n\u001B[0;32m--> 187\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnet \u001B[38;5;241m=\u001B[39m \u001B[43mBertForQuestionAnswering\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workplace/diffmask/venv/lib/python3.9/site-packages/transformers/modeling_utils.py:2319\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   2304\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2305\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[1;32m   2306\u001B[0m     cached_file_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   2307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_dir\u001B[39m\u001B[38;5;124m\"\u001B[39m: cache_dir,\n\u001B[1;32m   2308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforce_download\u001B[39m\u001B[38;5;124m\"\u001B[39m: force_download,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2317\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m: commit_hash,\n\u001B[1;32m   2318\u001B[0m     }\n\u001B[0;32m-> 2319\u001B[0m     resolved_archive_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcached_file_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2321\u001B[0m     \u001B[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001B[39;00m\n\u001B[1;32m   2322\u001B[0m     \u001B[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001B[39;00m\n\u001B[1;32m   2323\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m resolved_archive_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m filename \u001B[38;5;241m==\u001B[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001B[1;32m   2324\u001B[0m         \u001B[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001B[39;00m\n",
      "File \u001B[0;32m~/workplace/diffmask/venv/lib/python3.9/site-packages/transformers/utils/hub.py:409\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001B[0m\n\u001B[1;32m    406\u001B[0m user_agent \u001B[38;5;241m=\u001B[39m http_user_agent(user_agent)\n\u001B[1;32m    407\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    408\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[0;32m--> 409\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    418\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    419\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RepositoryNotFoundError:\n\u001B[1;32m    424\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    425\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a local folder and is not a valid model identifier \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    426\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlisted on \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/models\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIf this is a private repository, make sure to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    427\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    428\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    429\u001B[0m     )\n",
      "File \u001B[0;32m~/workplace/diffmask/venv/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:120\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    118\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 120\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workplace/diffmask/venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1300\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001B[0m\n\u001B[1;32m   1297\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m temp_file_manager() \u001B[38;5;28;01mas\u001B[39;00m temp_file:\n\u001B[1;32m   1298\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdownloading \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, temp_file\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m-> 1300\u001B[0m     \u001B[43mhttp_get\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1301\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1302\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemp_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1303\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1305\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1306\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1308\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m local_dir \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1309\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStoring \u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in cache at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mblob_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/workplace/diffmask/venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:538\u001B[0m, in \u001B[0;36mhttp_get\u001B[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries)\u001B[0m\n\u001B[1;32m    528\u001B[0m     displayed_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(â€¦)\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdisplayed_name[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m20\u001B[39m:]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    530\u001B[0m progress \u001B[38;5;241m=\u001B[39m tqdm(\n\u001B[1;32m    531\u001B[0m     unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    532\u001B[0m     unit_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    536\u001B[0m     disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m(logger\u001B[38;5;241m.\u001B[39mgetEffectiveLevel() \u001B[38;5;241m==\u001B[39m logging\u001B[38;5;241m.\u001B[39mNOTSET),\n\u001B[1;32m    537\u001B[0m )\n\u001B[0;32m--> 538\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m r\u001B[38;5;241m.\u001B[39miter_content(chunk_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1024\u001B[39m):\n\u001B[1;32m    539\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m chunk:  \u001B[38;5;66;03m# filter out keep-alive new chunks\u001B[39;00m\n\u001B[1;32m    540\u001B[0m         progress\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mlen\u001B[39m(chunk))\n",
      "File \u001B[0;32m~/workplace/diffmask/venv/lib/python3.9/site-packages/requests/models.py:816\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 816\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    817\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m~/workplace/diffmask/venv/lib/python3.9/site-packages/urllib3/response.py:628\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp):\n\u001B[0;32m--> 628\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    630\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m    631\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[0;32m~/workplace/diffmask/venv/lib/python3.9/site-packages/urllib3/response.py:567\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[1;32m    564\u001B[0m fp_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_catcher():\n\u001B[0;32m--> 567\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    568\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    569\u001B[0m         flush_decoder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/workplace/diffmask/venv/lib/python3.9/site-packages/urllib3/response.py:533\u001B[0m, in \u001B[0;36mHTTPResponse._fp_read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m buffer\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    532\u001B[0m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[0;32m--> 533\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:459\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    457\u001B[0m     \u001B[38;5;66;03m# Amount is given, implement using readinto\u001B[39;00m\n\u001B[1;32m    458\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mbytearray\u001B[39m(amt)\n\u001B[0;32m--> 459\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b)[:n]\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    462\u001B[0m     \u001B[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001B[39;00m\n\u001B[1;32m    463\u001B[0m     \u001B[38;5;66;03m# and self.chunked\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:503\u001B[0m, in \u001B[0;36mHTTPResponse.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    498\u001B[0m         b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmemoryview\u001B[39m(b)[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength]\n\u001B[1;32m    500\u001B[0m \u001B[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001B[39;00m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001B[39;00m\n\u001B[1;32m    502\u001B[0m \u001B[38;5;66;03m# (for example, reading in 1k chunks)\u001B[39;00m\n\u001B[0;32m--> 503\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m n \u001B[38;5;129;01mand\u001B[39;00m b:\n\u001B[1;32m    505\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    506\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    507\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1238\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1239\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1240\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1242\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1243\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1098\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1099\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "model = BertQuestionAnsweringSquadDiffMask.load_from_checkpoint(hparams.model_path).to(device)\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and plotting DiffMask attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "question = \"Where did the Broncos practice for the Super Bowl ?\"\n",
    "context = \"\"\"The Panthers used the San Jose State practice facility and \\\n",
    "stayed at the San Jose Marriott . The Broncos practiced at Stanford University \\\n",
    "and stayed at the Santa Clara Marriott .\"\"\"\n",
    "\n",
    "inputs_dict = {\n",
    "    k: v.to(device)\n",
    "    for k, v in model.tokenizer.encode_plus(\n",
    "        question,\n",
    "        context,\n",
    "        max_length=384,\n",
    "        pad_to_max_length=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).items()\n",
    "}\n",
    "inputs_dict[\"mask\"] = inputs_dict[\"attention_mask\"]\n",
    "del inputs_dict[\"attention_mask\"]\n",
    "\n",
    "question = model.tokenizer.tokenize(question)\n",
    "context = model.tokenizer.tokenize(context)\n",
    "tokens = [\"[CLS]\"]  + question + [\"[SEP]\"]  + context + [\"[SEP]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "logits_start_orig, logits_end_orig, expected_L0_full = model.forward_explainer(\n",
    "    **inputs_dict, attribution=True\n",
    ")\n",
    "attributions = expected_L0_full.exp()[0,:len(tokens)].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_squad_attributions(attributions, tokens, context, question, inputs_dict, logits_start_orig, logits_end_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print_attributions(tokens, attributions.sum(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing statistics on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"./datasets/squad/dev-v1.1_bert-large-uncased-whole-word-masking-finetuned-squad-mapping.json\", \"r\"\n",
    ") as f:\n",
    "    model.val_dataset_orig_offsets = json.load(f)\n",
    "    \n",
    "model.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "val_dataset_orig = [e for e in model.val_dataset_orig.items()]\n",
    "for i, batch in tqdm(enumerate(model.val_dataloader()), total=len(model.val_dataset) // model.hparams.batch_size):\n",
    "    input_ids, mask, token_type_ids, _, _ = tuple(e.to(device) for e in batch)\n",
    "\n",
    "    logits_start, logits_end, expected_L0_full = model.forward_explainer(\n",
    "        input_ids, mask, token_type_ids, attribution=True\n",
    "    )\n",
    "    attributions = expected_L0_full.exp().cpu()\n",
    "\n",
    "    for j in range(attributions.shape[0]):\n",
    "        question_offset = len(val_dataset_orig[i * model.hparams.batch_size + j][1][\"question\"])\n",
    "        val_dataset_orig[i * model.hparams.batch_size + j][1][\"question\"] = (\n",
    "            val_dataset_orig[i * model.hparams.batch_size + j][1][\"question\"],\n",
    "            attributions[j, 1:1 + question_offset]\n",
    "        )\n",
    "\n",
    "        val_dataset_orig[i * model.hparams.batch_size + j][1][\"context\"] = (\n",
    "            val_dataset_orig[i * model.hparams.batch_size + j][1][\"context\"],\n",
    "            attributions[j, 2 + question_offset:mask[j].sum().item() - 1]\n",
    "        )\n",
    "        \n",
    "        val_dataset_orig[i * model.hparams.batch_size + j][1][\"answer_model\"] = [\n",
    "            logits_start[j].argmax(-1).item() - question_offset - 2,\n",
    "            logits_end[j].argmax(-1).item() - question_offset - 2,\n",
    "        ]\n",
    "        val_dataset_orig[i * model.hparams.batch_size + j][1][\"special\"] = attributions[\n",
    "            j, [0, 1 + question_offset, mask[j].sum().item() - 1]\n",
    "        ]\n",
    "        \n",
    "val_dataset_orig = dict(val_dataset_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "question_use = torch.stack([v[\"question\"][1].mean(0) for k, v in val_dataset_orig.items()]).mean(0)\n",
    "context_use = torch.stack([v[\"context\"][1].mean(0) for k, v in val_dataset_orig.items()]).mean(0)\n",
    "answer_model_use = torch.stack([\n",
    "    (v[\"context\"][1][v[\"answer_model\"][0]] + v[\"context\"][1][v[\"answer_model\"][1]]) / 2\n",
    "    for k, v in val_dataset_orig.items()\n",
    "]).mean(0)\n",
    "\n",
    "answer_correct_use = [[(v[\"context\"][1][s] + v[\"context\"][1][e]) / 2\n",
    "               for s, e in v[\"answer_offsets\"]]\n",
    "              for k, v in val_dataset_orig.items()]\n",
    "answer_correct_use = torch.stack([torch.stack(e).max(0).values for e in answer_correct_use]).mean(0)\n",
    "\n",
    "answer_wrong_use = [[(v[\"context\"][1][s] + v[\"context\"][1][e]) / 2\n",
    "               for s, e in v[\"answer_offsets\"]]\n",
    "              for k, v in val_dataset_orig.items() if v[\"answer_model\"] not in v[\"answer_offsets\"]]\n",
    "answer_wrong_use = torch.stack([torch.stack(e).max(0).values for e in answer_wrong_use]).mean(0)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.plot(question_use, marker=\"o\", linewidth=2, label=\"Question\")\n",
    "plt.plot(context_use, marker=\"^\", linewidth=2, label=\"Passage\")\n",
    "plt.plot(answer_correct_use, marker=\"X\", linewidth=2, label=\"Ground truth\")\n",
    "plt.plot(answer_wrong_use, marker=\"s\", linewidth=2, label=\"G.t. w/ wrong prediciton\")\n",
    "\n",
    "plt.xticks(torch.arange(0, 25, 4) + .5, [\"E\"] + list(range(4, 25, 4)), size=20)\n",
    "plt.yticks(torch.linspace(0, 1, 6), [\"{:.1f}\".format(e) for e in torch.linspace(0, 1, 6)], size=20)\n",
    "\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.legend(fontsize=16, loc=\"lower left\") #, frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "counts = {\n",
    "    k: defaultdict(list) for k in (\"question\", \"context\", \"all\")\n",
    "}\n",
    "for k, v in tqdm(model.val_dataset_orig_offsets.items()):\n",
    "    if k in val_dataset_orig:\n",
    "        e = val_dataset_orig[k]\n",
    "        for g in (\"question\", \"context\"):\n",
    "            for f, s in zip([f[2] for f in v[g]], e[g][-1].sum(-1)):\n",
    "                counts[g][f].append(s)\n",
    "                counts[\"all\"][f].append(s)\n",
    "        counts[\"all\"][\"[CLS]\"].append(e[\"special\"][0].sum(-1))\n",
    "        counts[\"all\"][\"[SEP] 1\"].append(e[\"special\"][1].sum(-1))\n",
    "        counts[\"all\"][\"[SEP] 2\"].append(e[\"special\"][2].sum(-1))\n",
    "                \n",
    "for g in (\"question\", \"context\", \"all\"):\n",
    "    print(g)\n",
    "    \n",
    "    counts[g] = sorted([(k, torch.stack(v)) for k, v in counts[g].items()])\n",
    "    counts[g] = [(k, (v.mean(), v.std())) for k, v in counts[g]]\n",
    "    counts[g] = sorted(counts[g], key=lambda x: x[1][0])\n",
    "\n",
    "    fig = plt.figure(figsize=(4, len(counts[g]) / 2))\n",
    "    plt.barh(range(len(counts[g])),\n",
    "            [m.item() for k, (m, s) in counts[g]],\n",
    "            xerr=[s.item() for k, (m, s) in counts[g]],\n",
    "            capsize=3)\n",
    "    plt.yticks(torch.arange(len(counts[g])), [k for k, (m, s) in counts[g]], size=16)\n",
    "    plt.xticks(torch.arange(0, 25, 4) + .5, [\"E\"] + list(range(4, 25, 4)), size=16)\n",
    "    \n",
    "    plt.xlim(-4, 32)\n",
    "    plt.margins(y=.5 / len(counts[g]))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "counts = {\n",
    "    k: defaultdict(list) for k in (\"question\", \"context\")\n",
    "}\n",
    "for k, v in tqdm(model.val_dataset_orig_offsets.items()):\n",
    "    if k in val_dataset_orig:\n",
    "        e = val_dataset_orig[k]\n",
    "        for g in (\"question\", \"context\"):\n",
    "            for f, s in zip([f[-1] if len(f) == 7 else \"OTHER\" for f in v[g]], e[g][-1].sum(-1)):\n",
    "                counts[g][f].append(s)\n",
    "                \n",
    "for g in (\"question\", \"context\"):\n",
    "    print(g)\n",
    "    \n",
    "    counts[g] = sorted([(k, torch.stack(v)) for k, v in counts[g].items()])\n",
    "    counts[g] = [(k, (v.mean(), v.std())) for k, v in counts[g]]\n",
    "    counts[g] = sorted(counts[g], key=lambda x: x[1][0])\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, len(counts[g]) / 2))\n",
    "    plt.barh(range(len(counts[g])),\n",
    "            [m.item() for k, (m, s) in counts[g]],\n",
    "            xerr=[s.item() for k, (m, s) in counts[g]],\n",
    "            capsize=3)\n",
    "    plt.yticks(torch.arange(len(counts[g])), [k for k, (m, s) in counts[g]], size=16)\n",
    "    plt.xticks(torch.arange(0, 25, 4) + .5, [\"E\"] + list(range(4, 25, 4)), size=16)\n",
    "    \n",
    "    plt.xlim(-4, 32)\n",
    "    plt.margins(y=.5 / len(counts[g]))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
